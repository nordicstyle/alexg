---
layout: single
read_time: false
comments: false
share: false
title: Research Highlights
permalink: /research/
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: /assets/images/trinity.jpg
  cta_url: "#featured"
  caption: "Photo: [Olly McMillan](https://www.youtube.com/watch?v=kQkZeXHfgwA&t=1s)"
excerpt: "Geometry and Uncertainty in Deep Learning for Computer Vision<br><br><br>"
---

## Bayesian Deep Learning

## Scene Understanding
<iframe width="560" height="315" src="https://www.youtube.com/embed/CxanE_W46ts?color=white&theme=light"></iframe>
SegNet is a deep learning architecture capable of real time semantic segmentation of pixels in an image. The system can segment road, road markings, obstacles, pedestrians and traffic among other important objects to consider while driving. [You can view an online demo here](http://mi.eng.cam.ac.uk/projects/segnet/).

## Stereo Vision

## Localisation
<iframe width="560" height="315" src="https://www.youtube.com/embed/u0MVbL_RyPU?color=white&theme=light"></iframe>
PoseNet shows we can use convolutional neural networks for robust pose localisation. It uses a deep learning to regress six degree of freedom camera pose relative to a landmark. PoseNet can estimate the camera's location and orientation over large outdoor urban environments or inside buildings. It takes only 5ms to do this from a single colour image. [You can view an online demo here](http://mi.eng.cam.ac.uk/projects/relocalisation/).

---

# Other Projects

## Object Following Quadcopter
<figure class="half">
    <a><iframe width="560" height="315" src="https://www.youtube.com/embed/jDHYdiEp-eQ?color=white&theme=light"></iframe></a>
    <figcaption>For Alex's final year undergraduate research project at Auckland University he developed an autonomous object following control system on a quadcopter using on-board, monocular vision. The quadcopter was able to track trained objects using computer vision processed on-board the quadcopter. The object's x, y coordinate and scale from the on-board video is used to regulate the yaw, height and range respectively. He published this work at the IEEE conference on Unmanned Aircraft Systems 2014.</figcaption>
</figure>

## Augmented Reality
<figure class="half">
    <a><iframe width="560" height="315" src="https://www.youtube.com/embed/lw-LNR_bfeo?color=white&theme=light"></iframe></a>
    <figcaption>Alex created custom Augmented Reality software to convey design information to clients while working as an engineering consultant at Beca. It was a standalone hardware system using Microsoft Kinect 2.0 and the Unity framework which was able to be deployed for a range of applications.</figcaption>
</figure>

## Firefighting
<figure class="half">
    <a><iframe width="560" height="315" src="https://www.youtube.com/embed/js2hVfB0frA?color=white&theme=light"></iframe></a>
    <figcaption>This was a final year design project in the University of Auckland Mechatronics course. Alex's team's solution was a robot which could autonomously path plan and localise flames (candles), extinguishing them with a CO2 system. The robot was designed and constructed with 3D printing technology. [More information is available on the home page](http://homepages.engineering.auckland.ac.nz/~pxu012/mechatronics2013/group2/home.html).</figcaption>
</figure>
